{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Import necessary libraries\n",
    "from backtesting import Backtest, Strategy\n",
    "from backtesting.test import SMA\n",
    "from backtesting.lib import crossover\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import LSTM, Dense, Input, Dropout\n",
    "from keras.models import load_model, Model\n",
    "from keras.callbacks import EarlyStopping, Callback\n",
    "import os\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define a function to read the data file\n",
    "def _read_file(filepath):\n",
    "    data = pd.read_csv(filepath, index_col=0, parse_dates=True, infer_datetime_format=True)\n",
    "    \n",
    "    # Convert prices to Î¼BTC\n",
    "    data = (data / 1e6).assign(Volume=data.Volume * 1e6)\n",
    "    \n",
    "    # Strip datetime, adj_close values for backtest\n",
    "    data.drop(columns=['Datetime'], inplace=True)\n",
    "    data.drop(columns=['adj_close'], inplace=True)\n",
    "    \n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', 1000)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Read the data file\n",
    "retrain_model = False\n",
    "\n",
    "if retrain_model:\n",
    "    batch_size = 1\n",
    "    data = data = _read_file('../../candles/BTCUSDT_1min.csv')\n",
    "else:\n",
    "    batch_size = 32\n",
    "    data = _read_file('../../candles/binance_bars_APT_1m.csv') # BTCUSDT_1min BTCUSDT_30min binance_bars_LINK_1m BTCUSDT_2023-3-06_1min binance_bars_RUNE_1m binance_bars_SOL_1m binance_bars_APT_1m binance_bars_EOS_1m\n",
    "data = data.sort_index()\n",
    "\n",
    "'''\n",
    "Full         2017-08-17 2022-12-31 (training dataset of hope_BTC_1m_VWAP_FULL_2017-08-17_to_2022-12-31)\n",
    "Bullrun      2021-02-01 2022-08-31 (initial training dataset of \"hope_bullrun_1m_VPS_trained\" model)\n",
    "Downtrend    2021-05-09 2021-05-24\n",
    "Uptrend      2021-01-27 2021-02-21\n",
    "Sidetrend    2021-05-18 2021-06-10\n",
    "Final        2021-04-25 2021-06-10\n",
    "\n",
    "Unseen/Untrained Data (all after 2022-12-31)\n",
    "Sideway          2023-03-06 2023-04-25\n",
    "Downtrend        2023-07-21 2023-08-23\n",
    "\n",
    "\n",
    "TODO :: Add more bull bear sideway periods after 2022-12-31\n",
    "'''\n",
    "\n",
    "# Define the Backtest date range\n",
    "start_date = \"2023-03-06\"\n",
    "end_date = \"2023-04-25\"\n",
    "\n",
    "\n",
    "# Resample to 4-minute timeframe\n",
    "# data = data.resample('1T').agg({\n",
    "#     'Open': 'first',\n",
    "#     'High': 'max',\n",
    "#     'Low': 'min',\n",
    "#     'Close': 'last',\n",
    "#     'Volume': 'sum'\n",
    "# }).dropna()\n",
    "\n",
    "\n",
    "\n",
    "debug_predict = False\n",
    "debug_predict_knn_lstm = False"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/alca/tf/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/alca/tf/lib/python3.11/site-packages/backtesting/test/__init__.py:8: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  return pd.read_csv(join(dirname(__file__), filename),\n",
      "/home/alca/tf/lib/python3.11/site-packages/backtesting/test/__init__.py:8: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  return pd.read_csv(join(dirname(__file__), filename),\n",
      "2023-10-11 06:00:24.494119: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-11 06:00:24.494156: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-11 06:00:24.494198: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-11 06:00:24.501430: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-11 06:00:25.077899: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Define the TP percentage (e.g., 4%)\n",
    "tp_percentage = 4 # You can change this value to any percentage you want\n",
    "sl_percentage = 4\n",
    "\n",
    "# Define a function for the indicators\n",
    "def BBANDS(data, n_lookback, n_std):\n",
    "    \"\"\"Bollinger bands indicator\"\"\"\n",
    "    hlc3 = (data.High + data.Low + data.Close) / 3\n",
    "    mean, std = hlc3.rolling(n_lookback).mean(), hlc3.rolling(n_lookback).std()\n",
    "    upper = mean + n_std*std\n",
    "    lower = mean - n_std*std\n",
    "    return upper, lower\n",
    "\n",
    "def calculate_vwap(data, period):\n",
    "    data['TP'] = (data['High'] + data['Low'] + data['Close']) / 3\n",
    "    data['CumVolume'] = data['Volume'].cumsum()\n",
    "    data['CumPV'] = (data['TP'] * data['Volume']).cumsum()\n",
    "    data['VWAP'] = data['CumPV'] / data['CumVolume']\n",
    "    data.drop(['TP', 'CumVolume', 'CumPV'], axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "def calculate_hidden_divergence(data):\n",
    "    data['HiddenBullishDivergence'] = (data['Low'].shift(1) < data['Low']) & (data['VWAP'].shift(1) > data['VWAP'])\n",
    "    data['HiddenBearishDivergence'] = (data['High'].shift(1) > data['High']) & (data['VWAP'].shift(1) < data['VWAP'])\n",
    "    return data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Extract necessary data and calculate features\n",
    "close = data.Close.values\n",
    "volume = data.Volume.values\n",
    "sma10 = SMA(data.Close, 10)\n",
    "sma20 = SMA(data.Close, 20)\n",
    "sma50 = SMA(data.Close, 50)\n",
    "sma100 = SMA(data.Close, 100)\n",
    "sma200 = SMA(data.Close, 200)\n",
    "upper, lower = BBANDS(data, 20, 2)\n",
    "\n",
    "# Design matrix / independent features:\n",
    "\n",
    "# Price-derived features\n",
    "data['X_SMA10'] = (close - sma10) / close\n",
    "data['X_SMA20'] = (close - sma20) / close\n",
    "data['X_SMA50'] = (close - sma50) / close\n",
    "data['X_SMA100'] = (close - sma100) / close\n",
    "data['X_SMA200'] = (close - sma200) / close\n",
    "\n",
    "data['X_DELTA_SMA10'] = (sma10 - sma20) / close\n",
    "data['X_DELTA_SMA20'] = (sma20 - sma50) / close\n",
    "data['X_DELTA_SMA50'] = (sma50 - sma100) / close\n",
    "data['X_DELTA_SMA100'] = (sma100 - sma200) / close\n",
    "\n",
    "# Indicator features\n",
    "data['X_MOM'] = data.Close.pct_change(periods=2)\n",
    "data['X_BB_upper'] = (upper - close) / close\n",
    "data['X_BB_lower'] = (lower - close) / close\n",
    "data['X_BB_width'] = (upper - lower) / close\n",
    "\n",
    "# Some datetime features for good measure\n",
    "data['X_day'] = data.index.dayofweek\n",
    "data['X_hour'] = data.index.hour\n",
    "\n",
    "# Get Volume\n",
    "data['Volume'] = data.Volume\n",
    "\n",
    "# Apply VWAP calculation\n",
    "data = calculate_vwap(data, period=20)\n",
    "# Apply hidden divergence calculation\n",
    "data = calculate_hidden_divergence(data)\n",
    "\n",
    "data = data.dropna().astype(float)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Define functions to get model design matrix and dependent variable\n",
    "def get_X(data):\n",
    "    \"\"\"Return model design matrix X\"\"\"\n",
    "    return data.filter(like='X').values\n",
    "\n",
    "def get_y(data):\n",
    "    \"\"\"Return dependent variable y\"\"\"\n",
    "    y = data.Close.pct_change(48).shift(-48)  # Returns after roughly two days\n",
    "    y[abs(y) < .004] = 0\n",
    "    y[y > 0] = 1\n",
    "    y[y < 0] = -1\n",
    "    return y\n",
    "\n",
    "def get_clean_Xy(df):\n",
    "    \"\"\"Return (X, y) cleaned of NaN values\"\"\"\n",
    "    X = get_X(df)\n",
    "    y = get_y(df).values\n",
    "    isnan = np.isnan(y)\n",
    "    X = X[~isnan]\n",
    "    y = y[~isnan]\n",
    "    return X, y\n",
    "\n",
    "# Prepare the data for modeling\n",
    "data = data.loc[start_date:end_date]\n",
    "X, y = get_clean_Xy(data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Calculate the percentage of data to use for training\n",
    "train_pct = 0.8  # set the percentage to use for training\n",
    "n_train = int(len(data) * train_pct)\n",
    "print(f\"Using {train_pct * 100}% of the data ({n_train} rows) for training\")\n",
    "\n",
    "def create_lstm_model(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = LSTM(128, return_sequences=True)(input_layer)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(loss='mae', optimizer='adamax', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def reshape_input_data(X, y, time_steps):\n",
    "    num_samples, num_features = X.shape\n",
    "    X_reshaped = np.zeros((num_samples - time_steps + 1, time_steps, num_features))\n",
    "    y_reshaped = y[time_steps - 1:]\n",
    "    for i in range(len(X_reshaped)):\n",
    "        X_reshaped[i] = X[i:i + time_steps]\n",
    "    return X_reshaped, y_reshaped\n",
    "\n",
    "if debug_predict == True:\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "X_train_reshaped, y_train_reshaped = reshape_input_data(X_train, y_train, time_steps=10)  # Adjust time_steps as needed"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using 80.0% of the data (53504 rows) for training\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def train_lstm_model(X_train, y_train, time_steps=10, epochs=150):\n",
    "    input_shape = (time_steps, X_train.shape[2])\n",
    "\n",
    "    model = create_lstm_model(input_shape)\n",
    "    X_train_reshaped = X_train\n",
    "\n",
    "    if debug_predict == True:\n",
    "        print(\"X_train_reshaped shape:\", X_train_reshaped.shape)\n",
    "        print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "    # Define early stopping and custom progress callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=True)\n",
    "    \n",
    "    class TrainingProgressCallback(Callback):\n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            # Calculate the percentage completed\n",
    "            percent_complete = (epoch + 1) / epochs * 100\n",
    "            print(f\"\\n\\n{percent_complete:.2f}% complete - Loss: {logs['loss']:.4f} - Val Loss: {logs['val_loss']:.4f}\\n\")\n",
    "    \n",
    "    progress_callback = TrainingProgressCallback()\n",
    "\n",
    "    # Train the model with early stopping and custom progress callback\n",
    "    history = model.fit(\n",
    "        X_train_reshaped, y_train, \n",
    "        epochs=epochs, \n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.2,  # Use 20% of training data for validation\n",
    "        callbacks=[early_stopping, progress_callback],  # Add the callbacks\n",
    "        use_multiprocessing=True,\n",
    "        workers=8 # have the feeling the GPU has to less wait for input queues\n",
    "    )\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "def retrain_lstm_model(model_filename, new_data, epochs=150):\n",
    "    # Load the existing model\n",
    "    existing_model = load_model(model_filename)\n",
    "\n",
    "    # Prepare the new data for retraining\n",
    "    X_new, y_new = get_clean_Xy(new_data)\n",
    "    X_new_reshaped, y_new_reshaped = reshape_input_data(X_new, y_new, time_steps=10)\n",
    "\n",
    "    # Retrain the model with the new data\n",
    "    retrained_model, _ = train_lstm_model(X_new_reshaped, y_new_reshaped, epochs=epochs)\n",
    "\n",
    "    # Save the updated model (optional)\n",
    "    retrained_model.save(model_filename)\n",
    "    \n",
    "    return retrained_model\n",
    "\n",
    "def save_lstm_model(model, filename):\n",
    "    model.save(filename)\n",
    "\n",
    "def load_lstm_model(filename):\n",
    "    return load_model(filename)\n",
    "\n",
    "# Load the saved LSTM model from a file if it exists, or create and train a new one\n",
    "\n",
    "lstm_model_filename = f'hope_BTC_1m_VWAP_FULL_2017-08-17_to_2022-12-31.h5'\n",
    "if os.path.exists(lstm_model_filename):\n",
    "    lstm_model = load_lstm_model(lstm_model_filename)\n",
    "    print(\"Loaded LSTM model from file:\", lstm_model_filename)\n",
    "    if retrain_model:\n",
    "        print(f\"Preparing {lstm_model_filename} for Retraining over {start_date} to {end_date}\")\n",
    "        retrained_model = retrain_lstm_model(lstm_model_filename, data, epochs=150)\n",
    "else:\n",
    "    print(\"LSTM Model file not found. Creating a new LSTM model and training it.\")\n",
    "    # Unpack the trained model from the tuple\n",
    "    lstm_model, _ = train_lstm_model(X_train_reshaped, y_train_reshaped, epochs=150)\n",
    "\n",
    "    # Save the unpacked model\n",
    "    lstm_model.save(lstm_model_filename)\n",
    "    print('Creating a new LSTM model Done!')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2023-10-11 06:00:26.366509: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-11 06:00:26.424564: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-11 06:00:26.424780: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-11 06:00:26.426106: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-11 06:00:26.426291: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-11 06:00:26.426462: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-11 06:00:26.501960: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-11 06:00:26.502158: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-11 06:00:26.502338: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-11 06:00:26.502470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6806 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:28:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded LSTM model from file: hope_BTC_1m_VWAP_FULL_2017-08-17_to_2022-12-31.h5\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def predict_with_lstm(model, data):\n",
    "    # Ensure data has 10 time steps\n",
    "    if data.shape[1] < 10:\n",
    "        # If data has fewer than 10 time steps, pad it with zeros\n",
    "        data = np.pad(data, ((0, 0), (10 - data.shape[1], 0), (0, 0)), 'constant')\n",
    "    elif data.shape[1] > 10:\n",
    "        # If data has more than 10 time steps, truncate it to 10 time steps\n",
    "        data = data[:, -10:, :]\n",
    "\n",
    "    return model.predict(data)[0, 0]\n",
    "\n",
    "N_TRAIN = n_train\n",
    "\n",
    "class MLTrainOnceStrategy(Strategy):\n",
    "    # Initialize entry time\n",
    "    entry_time = None\n",
    "    \n",
    "    # Initialize entry price, TP price, and SL price\n",
    "    entry_price = None\n",
    "    tp_price = None\n",
    "    sl_price = None\n",
    "    current_position = None\n",
    "\n",
    "    def init(self):\n",
    "        print(\"Initializing strategy...\")\n",
    "        # Initialize the classifier if it's not already loaded\n",
    "        if not hasattr(self, 'clf'):\n",
    "            print(\"Initializing classifier...\")\n",
    "            # Init our model, a kNN classifier\n",
    "            self.clf = KNeighborsClassifier(7)\n",
    "            df = self.data.df.iloc[:N_TRAIN]\n",
    "            X, y = get_clean_Xy(df)\n",
    "            self.clf.fit(X, y)\n",
    "\n",
    "        # Set batch size and window size\n",
    "        self.batch_size = batch_size \n",
    "        self.window_size = 10\n",
    "\n",
    "        # Initialize batch data\n",
    "        self.batch_X = []\n",
    "        self.batch_y = []\n",
    "\n",
    "        # Plot y for inspection\n",
    "        self.I(get_y, self.data.df, name='y_true')\n",
    "\n",
    "        # Prepare empty, all-NaN forecast indicator\n",
    "        self.forecasts = self.I(lambda: np.repeat(np.nan, len(self.data)), name='forecast')\n",
    "\n",
    "\n",
    "    def next(self):\n",
    "        # Skip the training, in-sample data\n",
    "        if len(self.data) < N_TRAIN:\n",
    "            return\n",
    "        \n",
    "        # Check if there's an open position\n",
    "        if self.current_position:\n",
    "            # Check if TP or SL conditions are met\n",
    "            if crossover(self.data.Close, self.tp_price):\n",
    "                self.current_position.close()\n",
    "                # Calculate trade return based on entry and exit times\n",
    "                entry_price = self.data.df.loc[self.entry_time, 'Close']\n",
    "                exit_price = self.data.Close[-1]\n",
    "                trade_return = (exit_price / entry_price - 1) * 100\n",
    "                print(\"CROSSOVER TAKEPROFIT HiT! Trade Return [%]:\", trade_return)\n",
    "            elif crossover(self.data.Close, self.sl_price):\n",
    "                self.current_position.close()\n",
    "                entry_price = self.data.df.loc[self.entry_time, 'Close']\n",
    "                exit_price = self.data.Close[-1]\n",
    "                trade_return = (exit_price / entry_price - 1) * 100\n",
    "                print(\"CROSSOVER STOPLOSS HiT! Trade Return [%]:\", trade_return)\n",
    "\n",
    "        # Proceed only with out-of-sample data. Prepare some variables\n",
    "        high, low, close = self.data.High, self.data.Low, self.data.Close\n",
    "\n",
    "        # Forecast the next movement\n",
    "        X = get_X(self.data.df.iloc[-1:])\n",
    "        forecast = self.clf.predict(X)[0]\n",
    "\n",
    "        # Update the plotted \"forecast\" indicator\n",
    "        self.forecasts[-1] = forecast\n",
    "\n",
    "        # Predict using the LSTM model\n",
    "\n",
    "        lstm_forecast = 0\n",
    "        lookback = 9\n",
    "        \n",
    "        # Get index of last row \n",
    "        end_idx = len(self.data.df) - 1\n",
    "        \n",
    "        # Calculate start index \n",
    "        start_idx = end_idx - lookback\n",
    "        \n",
    "        # Handle case where there are not enough rows\n",
    "        if start_idx < 0:\n",
    "            start_idx = 0\n",
    "        \n",
    "        # Slice \n",
    "        df_latest_data = self.data.df.iloc[start_idx:end_idx+1] \n",
    "        \n",
    "        # Ensure at least 10 rows for prediction\n",
    "        if len(df_latest_data) >= 10:\n",
    "            X_latest_data = get_X(df_latest_data)\n",
    "            \n",
    "            # Get the number of layers dynamically\n",
    "            num_layers = X_latest_data.shape[0]\n",
    "        \n",
    "            if num_layers >= 10:\n",
    "                # Reshape for the LSTM model using the number of layers\n",
    "                X_latest_data_reshaped = X_latest_data.reshape(1, num_layers, 15)\n",
    "                lstm_forecast = predict_with_lstm(lstm_model, X_latest_data_reshaped)\n",
    "                if debug_predict:\n",
    "                    formatted_lstm_forecast = [\"{:.4f}\".format(val) for val in lstm_forecast]\n",
    "                    print(\"LSTM Forecast:\", formatted_lstm_forecast)\n",
    "                    print(\"X_latest_data shape:\", X_latest_data.shape)\n",
    "            else:\n",
    "                print(f\"Got only {num_layers} layers. Skipping prediction.\")\n",
    "        else:\n",
    "            print(f\"Got only {len(df_latest_data)} rows. Skipping prediction.\")\n",
    "    \n",
    "        # Make trading decisions based on both models' predictions\n",
    "        if forecast == 1 and lstm_forecast > 0.5 and not self.position.is_long:\n",
    "            # Store the entry time when a long position is opened\n",
    "            self.entry_time = self.data.index[-1]\n",
    "            self.buy(size=.1)\n",
    "            self.current_position = self.position  # Store the current position\n",
    "            \n",
    "            # Set TP and SL prices for the long position\n",
    "            self.tp_price = close[-1] * (1 + tp_percentage / 100)\n",
    "            self.sl_price = close[-1] * (1 - sl_percentage / 100)\n",
    "\n",
    "        elif forecast == -1 and lstm_forecast < 0.5 and not self.position.is_short:\n",
    "            # Store the entry time when a short position is opened\n",
    "            self.entry_time = self.data.index[-1]\n",
    "            self.sell(size=.1)\n",
    "            self.current_position = self.position  # Store the current position\n",
    "            \n",
    "            # Set TP and SL prices for the short position\n",
    "            self.tp_price = close[-1] * (1 - tp_percentage / 100)\n",
    "            self.sl_price = close[-1] * (1 + sl_percentage / 100)\n",
    "\n",
    "\n",
    "try:\n",
    "    # Create a Backtest instance using the defined strategy\n",
    "    bt = Backtest(data, MLTrainOnceStrategy, commission=.0002, margin=.05)\n",
    "\n",
    "    # Run the backtest\n",
    "    stats = bt.run()\n",
    "    \n",
    "    # Print the results\n",
    "    pprint(stats)\n",
    "    \n",
    "    # Save trade statistics to a CSV file\n",
    "    trades = stats['_trades']\n",
    "    trades.to_csv(f'trades.csv', index=False)\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle the exception here\n",
    "    print(f\"An error occurred during the backtest: {str(e)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Initializing strategy...\n",
      "Initializing classifier...\n",
      "1/1 [==============================] - 0s 485ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2023-10-11 06:00:27.565225: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8905\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 }
}
